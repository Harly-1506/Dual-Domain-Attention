{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1666633440520,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"q3X5wPnAbbft","outputId":"1270c4a2-a2b3-4d07-b744-3f661b71af16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Oct 24 17:43:59 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":814,"status":"ok","timestamp":1666695383065,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"LlWUNmgSyIxS","outputId":"e92119fb-ba92-4586-e62a-e8ca9b0552a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code\n"]}],"source":["%cd /content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":15776,"status":"ok","timestamp":1666695398837,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"qlor4sGsPS_Y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4e69168-9404-46ee-bbf7-dd43bc7f1001"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 61.5 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 68.2 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 71.9 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 73.7 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 59.7 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 71.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 70.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 74.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 74.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 70.3 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 68.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 72.0 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 74.0 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 72.2 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 532 kB 108 kB/s \n","\u001b[?25h"]}],"source":["!pip install wandb -qqq\n","!pip install pytorchcv -q"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12030,"status":"ok","timestamp":1666695410855,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"HxZDanzSsnGZ"},"outputs":[],"source":["import os\n","import json\n","import random\n","import warnings\n","\n","warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n","\n","import imgaug\n","import torch\n","import torch.multiprocessing as mp\n","import numpy as np\n","\n","\n","seed = 1234\n","random.seed(seed)\n","imgaug.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","from utils.datasets.fer2013_ds import FERDataset\n","# from models.vgg16_cbam import  VGG19_CBAM\n","from models.resnet_cbam import ResidualNet , cbam_resnet50\n","from models.vggnet import vgg16_bn, vgg19, vgg19_bn, vgg16\n","from models.resnet import resnet50\n","from models.vggnet_cbam import vgg16_cbam, vgg19_cbam\n","from models.vggnet_cbam_pre import vgg16_cbam_pre, vgg16_bn_cbam_pre, vgg19_bn_cbam_pre, MultiFCVGGnetCBam\n","from models.test_cbam import TestModel\n","from models.resmasking import *\n","from models.BamNetwork import *\n","from models.New_model import *\n","from models.ResNetVDSR import resnetvdsr_dropout1\n","\n","from utils.visualize.show_img import show_image_dataset\n","from trainer.fer2013_trainer import FER2013_Trainer\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666695410856,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"g_QNkZox-h0N","outputId":"66482317-5848-400f-f3e3-62f8fdabd1b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.1+cu113\n"]}],"source":["print(torch.__version__)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1666695410857,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"qNk6Y5vt1HI-"},"outputs":[],"source":["config_path = \"/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/configs/config_fer2013.json\""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":475,"status":"ok","timestamp":1666695411327,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"vi83DUB-K0RT"},"outputs":[],"source":["configs = json.load(open(config_path))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14482,"status":"ok","timestamp":1666695425806,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"e1nEwjudB1sb","outputId":"6ca7f502-31da-4455-d81a-d9e49c531457"},"outputs":[{"output_type":"stream","name":"stdout","text":["28709\n","3589\n","3589\n","3589\n"]}],"source":["train_loader = FERDataset( \"train\", configs)\n","val_loader = FERDataset(\"val\", configs)\n","test_loader_ttau = FERDataset(\"test\", configs, ttau = True, len_tta = 10) \n","test_loader = FERDataset(\"test\", configs, ttau = False, len_tta = 10) "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666695425807,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"Rtzif-77V0G5"},"outputs":[],"source":["# show_image_dataset(train_ds)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666695425808,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"-DjKCdQqwYHx"},"outputs":[],"source":["# model = resnet50_cbam()\n","# if torch.cuda.is_available():\n","#     model.cuda()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666695425809,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"r2tBLDuS1ty4"},"outputs":[],"source":["# n_inputs = model.classifier[6].in_features  \n","# model.classifier[6] = nn.Sequential(\n","#             nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n","#             nn.Linear(256, 7))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":14926,"status":"ok","timestamp":1666695440719,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"yVzD_Ng6Arjq","colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["e5f41a7ba8c741a9b0edf88e3f405f11","e22a2facb30445b9a8134d54c2f0c0b7","8e467e88625d4a468c107d474aa86de1","26280a4f8b2e4bc3bf3d9a6272400fb8","94620478f1f440babd344b175a37c5e3","c8378600d1ae40a08266f1ea95dcbc2a","32113849ad02420e99add461a04de9c7","ca1f6edc63654c9da47ab3259f4a444c","5ce24491f81d4f23a966fd6f0e7c1140","b7a94931f5774372bb8fdf5a37e229f1","053bcf7e34734b66bbab284aafea424c"]},"outputId":"784d16d9-9e4d-4dd0-c0db-b7a84a7fd5de"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/83.3M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f41a7ba8c741a9b0edf88e3f405f11"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":11}],"source":["# import torchvision\n","# model1 = vgg16_bn()\n","# model = resnet50(True, True, num_classes = 7)\n","# model1 = ResidualNet(\"ImageNet\", 50, 7, \"CBAM\")\n","# model = cbam_resnet50(in_channels=3, num_classes= 7 )\n","# model = vgg19()\n","# model = vgg19_bn()\n","# model1 = vgg16_bn(pretrained = True, batch_norm = True)\n","# model = vgg19_cbam(num_classes = 7)\n","# model = vgg16_bn_cbam_pre(num_classes=7)\n","# pretrained_model = torchvision.models.vgg16_bn(pretrained=True)\n","# model = TestModel(pretrained_model)\n","# model = MultiFCVGGnetCBam(model1)\n","# model = resmasking_dropout1()\n","# model = resnetvdsr_dropout1()\n","model = MyModel_dropout1()\n","state = torch.load(\"/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/checkpoints/Fer2013_trainers_V5_test_model22_2022Oct24_02.19\")\n","      \n","model.load_state_dict(state[\"net\"])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666695440719,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"},"user_tz":-420},"id":"-iCg11KKoz90"},"outputs":[],"source":["trainer = FER2013_Trainer(model, train_loader, val_loader, test_loader, test_loader_ttau, configs , wb = True)"]},{"cell_type":"code","source":["trainer.acc_on_test()\n","trainer.acc_on_test_ttau()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"ip-7mOqKxcUO","executionInfo":{"status":"error","timestamp":1666696219571,"user_tz":-420,"elapsed":778855,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"}},"outputId":"266de745-bb2a-4726-ee89-e21c4c9b7089"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["         100%|\u001b[32m██████████████████████████████\u001b[0m| 3589/3589 [12:58<00:00]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy on Test_ds: 72.165\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-373a9b079ec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_on_test_ttau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/trainer/fer2013_trainer.py\u001b[0m in \u001b[0;36macc_on_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on Test_ds: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Test_accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'FER2013_Trainer' object has no attribute 'wandb'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_cTPyOUKqkkS","outputId":"b89edf94-b67c-43f0-c919-063d751723a2","executionInfo":{"status":"error","timestamp":1666636856482,"user_tz":-420,"elapsed":3336571,"user":{"displayName":"Hải Trần Minh","userId":"10829535699963954986"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["------------SETTING UP WANDB--------------\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "]},{"name":"stdout","output_type":"stream","text":["··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharly\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"stream","name":"stdout","text":["------Wandb Init-------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/wandb/run-20221024_174550-3cu61hqb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/harly/Fer2013_trainers_V5/runs/3cu61hqb\" target=\"_blank\">test_model255555</a></strong> to <a href=\"https://wandb.ai/harly/Fer2013_trainers_V5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","-----------------------TRAINING MODEL-----------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|\u001b[34m██████████████████████████████████████████████████\u001b[0m| 599/599 [21:33<00:00]"]},{"output_type":"stream","name":"stdout","text":[" Loss: 0.2401 , Accuracy: 92.07%\n"]},{"output_type":"stream","name":"stderr","text":["\n","         100%|\u001b[32m██████████████████████████████\u001b[0m| 75/75 [01:01<00:00]"]},{"output_type":"stream","name":"stdout","text":[" Val_Loss: 1.1745 , Val_Accuracy: 69.90%\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2: 100%|\u001b[34m██████████████████████████████████████████████████\u001b[0m| 599/599 [21:28<00:00]"]},{"output_type":"stream","name":"stdout","text":[" Loss: 0.2236 , Accuracy: 92.22%\n"]},{"output_type":"stream","name":"stderr","text":["\n","         100%|\u001b[32m██████████████████████████████\u001b[0m| 75/75 [00:58<00:00]"]},{"output_type":"stream","name":"stdout","text":[" Val_Loss: 1.1484 , Val_Accuracy: 69.73%\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:  46%|\u001b[34m██████████████████████▉                           \u001b[0m| 275/599 [09:59<11:45]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/trainer/fer2013_trainer.py\", line 349, in Train_model\n","    self.step_per_train()\n","  File \"/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/trainer/fer2013_trainer.py\", line 208, in step_per_train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 396, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n","    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/trainer/fer2013_trainer.py\u001b[0m in \u001b[0;36mTrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;31m#loading best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/checkpoints/Fer2013_trainers_V5_test_model255555_2022Oct24_17.45'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-b8e0d63bd0cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/WorkSpace/AI_Research/EmotionTorch/code/trainer/fer2013_trainer.py\u001b[0m in \u001b[0;36mTrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprtin_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'traceback' has no attribute 'prtin_exc'"]}],"source":["if configs[\"distributed\"] == 1:\n","    ngpus = torch.cuda.device_count()\n","    print(ngpus)\n","    mp.spawn(trainer.Train_model, nprocs=ngpus, args=())\n","else:\n","    trainer.Train_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAPDxUtt75a-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"mount_file_id":"1k6-cn2J7ywrBL9YCCVTj3Mr9p0tlc7MI","authorship_tag":"ABX9TyP09ziy2JYBhXaHyHkyKht+"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e5f41a7ba8c741a9b0edf88e3f405f11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e22a2facb30445b9a8134d54c2f0c0b7","IPY_MODEL_8e467e88625d4a468c107d474aa86de1","IPY_MODEL_26280a4f8b2e4bc3bf3d9a6272400fb8"],"layout":"IPY_MODEL_94620478f1f440babd344b175a37c5e3"}},"e22a2facb30445b9a8134d54c2f0c0b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8378600d1ae40a08266f1ea95dcbc2a","placeholder":"​","style":"IPY_MODEL_32113849ad02420e99add461a04de9c7","value":"100%"}},"8e467e88625d4a468c107d474aa86de1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca1f6edc63654c9da47ab3259f4a444c","max":87306240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ce24491f81d4f23a966fd6f0e7c1140","value":87306240}},"26280a4f8b2e4bc3bf3d9a6272400fb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7a94931f5774372bb8fdf5a37e229f1","placeholder":"​","style":"IPY_MODEL_053bcf7e34734b66bbab284aafea424c","value":" 83.3M/83.3M [00:00&lt;00:00, 100MB/s]"}},"94620478f1f440babd344b175a37c5e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8378600d1ae40a08266f1ea95dcbc2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32113849ad02420e99add461a04de9c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca1f6edc63654c9da47ab3259f4a444c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ce24491f81d4f23a966fd6f0e7c1140":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7a94931f5774372bb8fdf5a37e229f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"053bcf7e34734b66bbab284aafea424c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}